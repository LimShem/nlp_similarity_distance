{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d980a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dic_1w = pd.read_csv(\"ngram/100k_data.csv\",sep=';',names=[0,1])\n",
    "dic_1w[0] = dic_1w[0].apply(lambda x: str(x).lower())\n",
    "\n",
    "def candidates(x,check=1):\n",
    "    \n",
    "    if check == 1:\n",
    "        if Is_in_dic(x):\n",
    "            return []\n",
    "    \n",
    "    alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "    edits = pd.DataFrame(None, columns=['candidates', 'error_type', 'error', 'c'])\n",
    "    splits = [(x[:i], x[i:]) for i in range(len(x) + 1)]\n",
    "    dels = []\n",
    "    inss = []\n",
    "    # only 1 edit distance from the inputted word\n",
    "    trans = [[L + R[1] + R[0] + R[2:], 'tran',  R[0] + R[1], R[1] + R[0]] for L, R in splits if len(R) > 1]\n",
    "    subs = [[L + c + R[1:], 'sub', R[0], L[-1:] + c + R[1:2]] for L, R in splits if R for c in alphabet]\n",
    "\n",
    "    for L, R in splits:\n",
    "        if R:\n",
    "            if L:\n",
    "                inss.append([L + R[1:], 'ins', R[0], L[-2:] + R[1:2]])\n",
    "            else:\n",
    "                inss.append([L + R[1:], 'ins', R[0], '>' + R[1:3]])\n",
    "        for c in alphabet:\n",
    "            try:\n",
    "                dels.append([L + c + R, 'del', c, L[-1]+c])\n",
    "            except:\n",
    "                dels.append([L + c + R, 'del', c, '>' + c + R[0:1]])\n",
    "\n",
    "    for item in dels:\n",
    "        if Is_in_dic(item[0]):\n",
    "            edits.loc[len(edits)] = item\n",
    "\n",
    "    for item in inss:\n",
    "        if Is_in_dic(item[0]):\n",
    "            edits.loc[len(edits)] = item\n",
    "\n",
    "    for item in trans:\n",
    "        if Is_in_dic(item[0]):\n",
    "            edits.loc[len(edits)] = item\n",
    "\n",
    "    for item in subs:\n",
    "        if Is_in_dic(item[0]):\n",
    "            edits.loc[len(edits)] = item\n",
    "\n",
    "    return edits.drop_duplicates(subset='candidates')\n",
    "\n",
    "def Is_in_dic(word):\n",
    "    if len(dic_1w[dic_1w[0] == word]) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def prior_calc(w):\n",
    "    sum_1w = dic_1w[1].sum()\n",
    "    temp = dic_1w[dic_1w[0] == w]\n",
    "    try:\n",
    "        prior = float(temp[1]) / sum_1w\n",
    "    except:\n",
    "        prior = 0\n",
    "    return prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43a9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err_freq = pd.read_csv('ngram/count_1edit.txt', delimiter='\\t', encoding='ISO-8859-1', header=None)\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz') + ['>']\n",
    "del_conf_mat = pd.DataFrame(None, columns=alphabet, index=alphabet)\n",
    "ins_conf_mat = pd.DataFrame(None, columns=alphabet, index=alphabet)\n",
    "sub_conf_mat = pd.DataFrame(None, columns=alphabet, index=alphabet)\n",
    "tran_conf_mat = pd.DataFrame(None, columns=alphabet, index=alphabet)\n",
    "\n",
    "for row in alphabet:\n",
    "    for col in alphabet:\n",
    "        temp1 = err_freq[err_freq[0] == col + '|' + col + row]\n",
    "        try:\n",
    "            del_conf_mat.loc[row, col] = int(temp1[1])\n",
    "        except:\n",
    "            del_conf_mat.loc[row, col] = 0\n",
    "\n",
    "        temp2 = err_freq[err_freq[0] == col + row + '|' + col]\n",
    "        try:\n",
    "            ins_conf_mat.loc[row, col] = int(temp2[1])\n",
    "        except:\n",
    "            ins_conf_mat.loc[row, col] = 0\n",
    "\n",
    "        temp3 = err_freq[err_freq[0] == row + '|' + col]\n",
    "        try:\n",
    "            sub_conf_mat.loc[row, col] = int(temp3[1])\n",
    "        except:\n",
    "            sub_conf_mat.loc[row, col] = 0\n",
    "\n",
    "        temp4 = err_freq[err_freq[0] == row + col + '|' + col + row]\n",
    "        try:\n",
    "            tran_conf_mat.loc[row, col] = int(temp4[1])\n",
    "        except:\n",
    "            tran_conf_mat.loc[row, col] = 0\n",
    "\n",
    "del_conf_mat.to_csv('del_mat.csv')\n",
    "ins_conf_mat.to_csv('ins_mat.csv')\n",
    "sub_conf_mat.to_csv('sub_mat.csv')\n",
    "tran_conf_mat.to_csv('tran_mat.csv')\n",
    "\n",
    "def likelihood_calc(type, error, c,idx):\n",
    "    \n",
    "    type=type[idx]\n",
    "    error = error[idx]\n",
    "    c = c[idx]\n",
    "    if type == 'del':\n",
    "        return del_conf_mat.loc[error, c[0]] / counter_2c(c[-2:])\n",
    "    elif type == 'ins':\n",
    "        return ins_conf_mat.loc[error, c[-1]] / counter_2c(c[-2:])\n",
    "    elif type == 'sub':\n",
    "        if len(c) == 2 and c[0] == error:\n",
    "            return sub_conf_mat.loc[error, c[-1]] / counter_2c(c[:2])\n",
    "        else:\n",
    "            return sub_conf_mat.loc[error, c[-2]] / counter_2c(c[:2])\n",
    "    elif type == 'tran':\n",
    "        return tran_conf_mat.loc[error[0], c[0]] / counter_2c(c)\n",
    "    \n",
    "def counter_2c(x):\n",
    "    return int(dic_1w[dic_1w[0] == x][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fcce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_words(word,check =1):\n",
    "    df = candidates(word,check)\n",
    "    if len(df) < 1:\n",
    "        return None\n",
    "    li_hd = []\n",
    "    \n",
    "#     for x in df.candidates:\n",
    "#         temp = df[df['candidates'] == x]\n",
    "#         li_hd.append(likelihood_calc(temp.error_type,temp.error,temp.c,temp.index.values[0]))\n",
    "\n",
    "#     df['likelihood'] = li_hd\n",
    "#     df['lh_scores'] = df['likelihood'].apply(lambda x: np.log(x))\n",
    "\n",
    "    prior_score = []\n",
    "    for x in df.candidates:\n",
    "        temp = df[df['candidates'] == x]\n",
    "        prior_score.append(prior_calc(x))\n",
    "\n",
    "    df['prior_score'] = prior_score\n",
    "    df['pr_scores'] = df['prior_score'].apply(lambda x: np.log(x))\n",
    "\n",
    "    df = df.sort_values('pr_scores',ascending=False)\n",
    "    return df.head(1) if check == 1 else df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320069a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# words = str(input())\n",
    "\n",
    "# k = re.sub(r\"[\\W]+\", ' ', words)\n",
    "# list_of_unknown_words = []\n",
    "# for x in k.lower().split(\" \"):\n",
    "#     if Is_in_dic(x) == False:\n",
    "#         list_of_unknown_words.append(x)\n",
    "# list_of_unknown_words.remove(\"\")\n",
    "# list_of_unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b233472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in set(list(list_of_unknown_words)):\n",
    "#     print(x)\n",
    "#     display(search_for_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd6d3b",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5339ee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Uplink verified</td>\n",
       "      <td>523545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0km to</td>\n",
       "      <td>116103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000s of</td>\n",
       "      <td>939476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100s of</td>\n",
       "      <td>539389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100th anniversary</td>\n",
       "      <td>158621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286353</th>\n",
       "      <td>zz zzz</td>\n",
       "      <td>203566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286354</th>\n",
       "      <td>zzz zzzz</td>\n",
       "      <td>203590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286355</th>\n",
       "      <td>Über uns</td>\n",
       "      <td>227462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286356</th>\n",
       "      <td>útil esta</td>\n",
       "      <td>140271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286357</th>\n",
       "      <td>über die</td>\n",
       "      <td>187069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0       1\n",
       "0        0Uplink verified  523545\n",
       "1                  0km to  116103\n",
       "2                1000s of  939476\n",
       "3                 100s of  539389\n",
       "4       100th anniversary  158621\n",
       "...                   ...     ...\n",
       "286353             zz zzz  203566\n",
       "286354           zzz zzzz  203590\n",
       "286355           Über uns  227462\n",
       "286356          útil esta  140271\n",
       "286357           über die  187069\n",
       "\n",
       "[286358 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_2w = pd.read_csv(\"ngram/count_2w.txt\",sep='\\t',names=[0,1])\n",
    "dic_2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e86cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_in_dic2(x):\n",
    "    return dic_2w[dic_2w[0].str.contains(x)] if len(dic_2w[dic_2w[0].str.contains(x)])>0 else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf6fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# words = str(input())\n",
    "\n",
    "# k = re.sub(r\"[\\W]+\", ' ', words)\n",
    "# list_of_unknown_words = []\n",
    "# split_w = k.lower().split(\" \")\n",
    "# for x in range(len(split_w)):\n",
    "#     temp = ' '.join(split_w[x:x+2])\n",
    "    \n",
    "#     if len(Is_in_dic2(temp))<1:\n",
    "#         print(temp)\n",
    "#         list_of_unknown_words.append(temp)\n",
    "# try:\n",
    "#     list_of_unknown_words.remove(\"\")\n",
    "# except:\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c832e59",
   "metadata": {},
   "source": [
    "## 1st way - Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c57c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9f647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def eu_distance(x,df,sc_dc=None):\n",
    "\n",
    "    combined_corpus = list(df[0].values)\n",
    "    combined_corpus.append(x)\n",
    "    vectorizer = CountVectorizer()\n",
    "    features = vectorizer.fit_transform(combined_corpus).todense() \n",
    "\n",
    "    score_dict = dict()\n",
    "    i = 0\n",
    "    for f in features:\n",
    "        score_dict[combined_corpus[i]] = euclidean_distances(features[len(features)-1], f)[0][0]\n",
    "        i+=1\n",
    "    return score_dict\n",
    "\n",
    "def prior_calc_bigram(w):\n",
    "    sum_2w = dic_2w[1].sum()\n",
    "    temp = dic_2w[dic_2w[0] == w]\n",
    "    try:\n",
    "        prior = float(temp[1]) / sum_2w\n",
    "    except:\n",
    "        prior = 0\n",
    "    return prior\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def search_best_candidate(sc_dc,word):\n",
    "    df = pd.DataFrame(sc_dc, index=['eu_values']).T.reset_index()\\\n",
    "                .rename(columns={'index':'candidates','eu_values':'eu_values'}).sort_values('eu_values')\n",
    "    df = df[df['eu_values'] > 0]\n",
    "    df['prior'] = df['candidates'].apply(lambda x: prior_calc_bigram(x))\n",
    "    df['log_prior'] = df['prior'].apply(lambda x: np.log(x))\n",
    "\n",
    "    df['lv_dist'] = df['candidates'].apply(lambda x: levenshteinDistance(x,word))\n",
    "    df = df.sort_values(['lv_dist','log_prior'])\n",
    "    return df.head(1)\n",
    "\n",
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ba1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in list_of_unknown_words:\n",
    "#     i = len(x)\n",
    "#     print(x)\n",
    "#     while i>0:\n",
    "#         temp_word = x[:i]\n",
    "#         search_word = Is_in_dic2(temp_word)\n",
    "#         if len(search_word)>0:\n",
    "#             sc_dc = eu_distance(x,search_word)\n",
    "#             display(search_best_candidate(sc_dc,x))         \n",
    "#             break\n",
    "#         i-=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ed8c4",
   "metadata": {},
   "source": [
    "## 2nd way - Bayesian Inference 2nd Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4da3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "\n",
    "# def printData(firstName, lastName):\n",
    "#     print(firstName)\n",
    "#     print(lastName)\n",
    "#     root.destroy()\n",
    "\n",
    "# def get_input():\n",
    "\n",
    "#     firstName = entry1.get()\n",
    "#     lastName = entry2.get()\n",
    "#     printData(firstName, lastName)\n",
    "\n",
    "\n",
    "# root = tk.Tk()\n",
    "# #Label 1\n",
    "# label1 = tk.Label(root,text = 'First Name')\n",
    "# label1.pack()\n",
    "# label1.config(justify = 'center')\n",
    "\n",
    "# entry1 = tk.Entry(root, width = 30)\n",
    "# entry1.pack()\n",
    "\n",
    "# label3 = tk.Label(root, text=\"Last Name\")\n",
    "# label3.pack()\n",
    "# label1.config(justify = 'center')\n",
    "\n",
    "# entry2 = tk.Entry(root, width = 30)\n",
    "# entry2.pack()\n",
    "\n",
    "# button1 = tk.Button(root, text = 'submit')\n",
    "# button1.pack() \n",
    "# button1.config(command = get_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07646ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = tk.Tk()\n",
    "# window.geometry(\"700x350\")\n",
    "# text_box = tk.Text(window)\n",
    "# text_box.pack()\n",
    "# text_box.insert(tk.INSERT, \"Maximum word count is 500 words\")\n",
    "# text_box.tag_add(\"start\", \"1.0\",\"1.7\")\n",
    "# text_box.tag_configure(\"start\", background=\"OliveDrab1\", foreground=\"black\")\n",
    "# text_box.pack()\n",
    "\n",
    "# button1 = tk.Button(window, text = 'submit')\n",
    "# button1.pack() \n",
    "# button1.config()\n",
    "\n",
    "\n",
    "# window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f63242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# import webbrowser\n",
    "# win = Tk()\n",
    "# win.geometry(\"700x350\")\n",
    "\n",
    "# def callback(event):\n",
    "#     book = event.widget\n",
    "#     text = book.cget(\"text\")\n",
    "#     book.config(bg='blue')\n",
    "#     print(text)\n",
    "#     win.destroy()\n",
    "\n",
    "# # Create a Label Widget\n",
    "# label= Label(win, text= \"Welcome to TutorialsPoint\", cursor= \"hand2\", foreground= \"green\", font= ('Aerial 18'))\n",
    "# label.pack(pady= 30)\n",
    "\n",
    "# # Define the URL to open\n",
    "# url= 'https://www.tutorialspoint.com/'\n",
    "\n",
    "# # Bind the label with the URL to open in a new tab\n",
    "# label.bind(\"<Button-1>\", callback)\n",
    "\n",
    "\n",
    "# win.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3392ca",
   "metadata": {},
   "source": [
    "## Asking and getting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff08afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "\n",
    "# def printData(firstName, lastName):\n",
    "#     print(firstName)\n",
    "#     print(lastName)\n",
    "    \n",
    "\n",
    "# def get_input():\n",
    "\n",
    "#     firstName = entry1.get(\"1.0\",END)\n",
    "# #     lastName = entry2.get()\n",
    "#     print(firstName)\n",
    "#     root.destroy()\n",
    "\n",
    "\n",
    "# root = tk.Tk()\n",
    "# root.geometry(\"700x700\")\n",
    "\n",
    "# #Label 1\n",
    "# label1 = tk.Label(root,text = 'First Name')\n",
    "# label1.pack()\n",
    "# label1.config(justify = 'center')\n",
    "\n",
    "# entry1 = tk.Text(root)\n",
    "# entry1.pack()\n",
    "\n",
    "\n",
    "# button1 = tk.Button(root, text = 'submit')\n",
    "# button1.pack() \n",
    "# button1.config(command = get_input)\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcad606",
   "metadata": {},
   "source": [
    "## Serious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e40c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "class saveInput:\n",
    "    def __init__(self):\n",
    "        self.words = ''\n",
    "        \n",
    "def get_input():\n",
    "    \n",
    "    firstName = entry1.get(\"1.0\",END)\n",
    "    saveWords.words = firstName\n",
    "    root.destroy()\n",
    "    \n",
    "def unigram_execution(words):\n",
    "    \n",
    "    k = re.sub(r\"[\\W]+\", ' ', words)\n",
    "    list_of_unknown_words = dict()\n",
    "    stat_words = 0\n",
    "    split_w = k.lower().split(\" \")\n",
    "    for x in range(len(split_w)):\n",
    "#         temp = ' '.join(split_w[x:x+2])\n",
    "        temp = stat_words+len(split_w[x])\n",
    "        temp_w = split_w[x]\n",
    "        if temp_w in list_of_unknown_words.keys():\n",
    "            n_w = [x for x in list_of_unknown_words.keys() if temp_w in x][-1].split(\" \")\n",
    "            temp_w = temp_w + ' '+  str(int(n_w[1])+1) if len(n_w) >= 2 else temp_w + \" 1\"\n",
    "        list_of_unknown_words[temp_w] = {'start': stat_words,'end':temp}\n",
    "        stat_words = temp+1\n",
    "        \n",
    "    \n",
    "    return list_of_unknown_words\n",
    "\n",
    "def bigram_execution(words):\n",
    "    import re\n",
    "\n",
    "#     k = re.sub(r\"[\\W]+\", ' ', words)\n",
    "    \n",
    "    list_of_unknown_words = dict()\n",
    "    split_w = words.lower().split(\" \")\n",
    "    start_words = 0\n",
    "    w_count = 0\n",
    "    for x in range(len(split_w)):\n",
    "        \n",
    "        temp = split_w[x:x+2]\n",
    "        j_temp = ' '.join(temp)\n",
    "\n",
    "        if j_temp in list_of_unknown_words.keys():\n",
    "            n_w = [x for x in list_of_unknown_words.keys() if j_temp in x][-1].split(\"_\")\n",
    "            print(n_w,j_temp)\n",
    "            j_temp = j_temp + '_'+  str(int(n_w[1])+1) if len(n_w) >= 2 else j_temp + \"_1\"\n",
    "            \n",
    "        if len(Is_in_dic2(j_temp))<1:\n",
    "            \n",
    "            list_of_unknown_words[j_temp] = {'start':start_words,'end':(start_words+len(temp[0])+len(temp[1])+1),\n",
    "                                             'array':[w_count,w_count+1]}\n",
    "            \n",
    "        start_words += len(temp[0])+1\n",
    "        w_count+=1\n",
    "        \n",
    "    try:\n",
    "        list_of_unknown_words.remove(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return list_of_unknown_words\n",
    "\n",
    "\n",
    "def get_words(data):\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_words = pd.DataFrame(data).T\n",
    "    df_words = df_words.sort_values(\"start\").reset_index()\n",
    "    return df_words\n",
    "\n",
    "def add_highlighter(df):\n",
    "    \n",
    "    inputted_words.tag_add(\"start\", '1.'+str(df[1]),'1.'+str(df[2]))\n",
    "    inputted_words.tag_config(\"start\", background= \"black\", foreground= \"white\")\n",
    "\n",
    "def generate_words_recommendation(p_words):\n",
    "    candidates_words_recommendation = pd.DataFrame()\n",
    "    for x in p_words['index']:\n",
    "        temp = x\n",
    "        print(temp)\n",
    "        i = len(temp)\n",
    "        while i>0:\n",
    "            temp_word = temp[:i]\n",
    "            search_word = Is_in_dic2(temp_word)\n",
    "            if len(search_word)>0:\n",
    "                sc_dc = eu_distance(x,search_word)\n",
    "                cd_res = search_best_candidate(sc_dc,x)\n",
    "                break\n",
    "            i-=1\n",
    "        candidates_words_recommendation = candidates_words_recommendation.append((cd_res))\n",
    "    return candidates_words_recommendation\n",
    "#     print(df[0],df[1],df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveWords = saveInput()\n",
    "\n",
    "root = Tk()\n",
    "root.geometry(\"700x700\")\n",
    "\n",
    "#Label 1\n",
    "label1 = Label(root,text = 'Maximum 500 words')\n",
    "label1.pack()\n",
    "label1.config(justify = 'center')\n",
    "\n",
    "entry1 = Text(root)\n",
    "entry1.pack()\n",
    "\n",
    "\n",
    "button1 = Button(root, text = 'submit')\n",
    "button1.pack() \n",
    "button1.config(command = get_input)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "011f35f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his intetion\n",
      "intetion during\n",
      "patent he\n",
      "such experiments\n",
      "experiments nor\n",
      "any partculars\n",
      "partculars respecting\n",
      "respecting them\n",
      "whether more\n",
      "of overcming\n",
      "overcming the\n",
      "the difficuties\n",
      "difficuties experienced\n",
      "experienced was\n",
      "was sugested\n",
      "sugested and\n",
      "tried or\n",
      "nor if\n",
      "was attemted\n",
      "attemted what\n"
     ]
    }
   ],
   "source": [
    "## Process all words\n",
    "\n",
    "k = re.sub(r\"[\\W]+\", ' ', saveWords.words)\n",
    "saveWords.words = k\n",
    "\n",
    "\n",
    "# Process the save words\n",
    "data = bigram_execution(saveWords.words)\n",
    "p_words = get_words(data)\n",
    "candidates_words_recommendation = generate_words_recommendation(p_words)\n",
    "p_words['candidate_words'] = candidates_words_recommendation['candidates'].values\n",
    "p_words['combined_words'] = p_words['index'].astype(str) + ' = ' + p_words['candidate_words'].astype(str)\n",
    "splitted_inputted_words = saveWords.words.split(\" \")\n",
    "\n",
    "for x,y in zip(p_words.array,p_words.candidate_words):\n",
    "    temp_split = y.split(\" \")\n",
    "    for z,i in zip(x,temp_split):\n",
    "        splitted_inputted_words[z] = i\n",
    "try:\n",
    "    splitted_inputted_words.remove(\"\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "## Bigram process ended\n",
    "\n",
    "## Unigram started\n",
    "unigram_execution = pd.DataFrame()\n",
    "i = 0\n",
    "for x in splitted_inputted_words:\n",
    "    temp_candidates = search_for_words(str(x).lower(),1)\n",
    "    if temp_candidates is not None:\n",
    "        temp_candidates['words'] = str(x)\n",
    "        temp_candidates['array'] = i\n",
    "        \n",
    "    unigram_execution = unigram_execution.append(temp_candidates)\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8119a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidates</th>\n",
       "      <th>eu_values</th>\n",
       "      <th>prior</th>\n",
       "      <th>log_prior</th>\n",
       "      <th>lv_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>his intention</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.352431e-06</td>\n",
       "      <td>-13.513606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>intention and</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.582964e-07</td>\n",
       "      <td>-14.398376</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patent in</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>4.932791e-07</td>\n",
       "      <td>-14.522191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such equipment</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.187241e-07</td>\n",
       "      <td>-14.015519</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiments for</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>5.148940e-07</td>\n",
       "      <td>-14.479305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>any particular</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.175399e-05</td>\n",
       "      <td>-11.351318</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>particular section</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.847154e-07</td>\n",
       "      <td>-14.539704</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>respecting the</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.969495e-06</td>\n",
       "      <td>-12.727119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whether my</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>5.952196e-07</td>\n",
       "      <td>-14.334335</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of overcoming</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>6.010925e-07</td>\n",
       "      <td>-14.324517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>overcoming the</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.107737e-06</td>\n",
       "      <td>-13.713191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the difficulties</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>6.215350e-06</td>\n",
       "      <td>-11.988489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>difficulties are</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.089347e-07</td>\n",
       "      <td>-14.311555</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experienced with</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.517951e-06</td>\n",
       "      <td>-13.398149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was suggested</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.373283e-06</td>\n",
       "      <td>-12.599624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>suggested and</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>4.705710e-07</td>\n",
       "      <td>-14.569319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tried on</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.243668e-07</td>\n",
       "      <td>-14.008650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nor in</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.955338e-06</td>\n",
       "      <td>-13.144947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was attempted</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>4.567143e-07</td>\n",
       "      <td>-14.599208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>attempted a</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>4.446942e-07</td>\n",
       "      <td>-14.625879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             candidates  eu_values         prior  log_prior  lv_dist\n",
       "3         his intention   1.414214  1.352431e-06 -13.513606        1\n",
       "773       intention and   2.000000  5.582964e-07 -14.398376        6\n",
       "4             patent in   1.414214  4.932791e-07 -14.522191        2\n",
       "4        such equipment   1.414214  8.187241e-07 -14.015519        6\n",
       "3       experiments for   1.414214  5.148940e-07 -14.479305        1\n",
       "1        any particular   1.414214  1.175399e-05 -11.351318        2\n",
       "930  particular section   2.000000  4.847154e-07 -14.539704        7\n",
       "0        respecting the   1.414214  2.969495e-06 -12.727119        1\n",
       "0            whether my   1.414214  5.952196e-07 -14.334335        3\n",
       "0         of overcoming   1.414214  6.010925e-07 -14.324517        1\n",
       "19       overcoming the   1.414214  1.107737e-06 -13.713191        1\n",
       "1      the difficulties   1.414214  6.215350e-06 -11.988489        1\n",
       "49     difficulties are   2.000000  6.089347e-07 -14.311555       10\n",
       "0      experienced with   1.414214  1.517951e-06 -13.398149        3\n",
       "0         was suggested   1.414214  3.373283e-06 -12.599624        1\n",
       "117       suggested and   1.414214  4.705710e-07 -14.569319        1\n",
       "0              tried on   1.414214  8.243668e-07 -14.008650        1\n",
       "7                nor in   1.414214  1.955338e-06 -13.144947        1\n",
       "0         was attempted   1.414214  4.567143e-07 -14.599208        1\n",
       "30          attempted a   1.732051  4.446942e-07 -14.625879        4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_words_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8717cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "# root.geometry(\"700x700\")\n",
    "root.attributes('-fullscreen', True)\n",
    "#Label 1\n",
    "label1 = Label(root,text = 'Maximum 500 words')\n",
    "# label1.pack()\n",
    "label1.config(justify = 'center')\n",
    "\n",
    "inputted_words = Text(root)\n",
    "inputted_words.insert(INSERT,saveWords.words + \"\\n\\n\\n\")\n",
    "p_words.apply(add_highlighter,axis=1)\n",
    "\n",
    "\n",
    "# Insert into it\n",
    "inputted_words.insert(INSERT,\"Processed words(aft bigram): \" + ' '.join(splitted_inputted_words))\n",
    "\n",
    "inputted_words_2 = Text(root)\n",
    "inputted_words_2.insert(INSERT,\"\\n\".join(p_words['combined_words'].values))\n",
    "inputted_words_2.insert(END,\"\\n\")\n",
    "\n",
    "if len(unigram_execution)> 0:\n",
    "    for x,y in zip(unigram_execution.candidates,unigram_execution.array):\n",
    "        splitted_inputted_words[y] = str(x)\n",
    "    unigram_execution['combined_words'] = unigram_execution['words'] + ' = ' + unigram_execution['candidates']\n",
    "    inputted_words.insert(INSERT,\"\\n\\nProcessed words(aft unigram): \" + ' '.join(splitted_inputted_words))\n",
    "    inputted_words_2.insert(INSERT,\"\\n\".join(unigram_execution['combined_words'].values))\n",
    "    inputted_words_2.insert(END,\"\\n\")\n",
    "\n",
    "\n",
    "# Label 2\n",
    "\n",
    "inputted_words_2.config(state=DISABLED)\n",
    "# inputted_words_2.pack()\n",
    "\n",
    "inputted_words.config(state=DISABLED)\n",
    "# inputted_words.pack()\n",
    "\n",
    "inputted_words_2.grid(column=2,row=0, padx=100, pady=10)  #,ipadx=0,padx=0,sticky=E+W)\n",
    "inputted_words.grid(column=1,row=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023316a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unigram_candidate(splitted_inputted_words = splitted_inputted_words):\n",
    "    selected_words = Lb1.curselection()[0]\n",
    "    df = search_for_words(str(splitted_inputted_words[selected_words]),0)\n",
    "    df['combined_candidates_score'] = df.candidates.astype(str) +' = '+df.pr_scores.apply(lambda x: round(x,2)).astype(str)\n",
    "    inputted_words_3.delete(1.0,\"end\")\n",
    "    if len(df)>0:\n",
    "        inputted_words_3.insert(INSERT,\"Recommendation for {} \\n\\n\".format(splitted_inputted_words[selected_words]) + \n",
    "                                    \"\\n\".join(df['combined_candidates_score'].values))\n",
    "    else:\n",
    "        inputted_words_3.insert(INSERT,\"No Recommendation for this word {}\".format(splitted_inputted_words[selected_words]))\n",
    "    \n",
    "inputted_words_3 = Text(root)\n",
    "inputted_words_3.grid(column=2,row=1, padx=100, pady=10)\n",
    "    \n",
    "## Listbox ##\n",
    "Lb1 = Listbox(root,width=len(splitted_inputted_words))\n",
    "i = 0\n",
    "for x in splitted_inputted_words:\n",
    "    \n",
    "    Lb1.insert(i+1, x)\n",
    "    i+=1\n",
    "\n",
    "Lb1.grid(column=1,row=1)\n",
    "\n",
    "button1 = Button(root, text = 'Find candidates')\n",
    "button1.grid(column=1,row=2) \n",
    "button1.config(command = find_unigram_candidate)\n",
    "\n",
    "## Listbox ##\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a28f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram_execution = pd.DataFrame()\n",
    "# i = 0\n",
    "# for x in splitted_inputted_words:\n",
    "#     temp_candidates = search_for_words(str(x),1)\n",
    "#     if temp_candidates is not None:\n",
    "#         temp_candidates['words'] = str(x)\n",
    "#         temp_candidates['array'] = i\n",
    "        \n",
    "#     unigram_execution = unigram_execution.append(temp_candidates)\n",
    "#     i+=1\n",
    "\n",
    "# for x,y in zip(unigram_execution.candidates,unigram_execution.array):\n",
    "#     splitted_inputted_words[y] = str(x)\n",
    "unigram_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_execution['combined_words'] = unigram_execution['words'] + ' = ' + unigram_execution['candidates']\n",
    "unigram_execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
